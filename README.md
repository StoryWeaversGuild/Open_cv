ðŸ“Œ Sentiment Analysis from Video using OpenCV and CNN
ðŸš€ Project Overview
This project performs Sentiment Analysis by detecting and classifying human emotions from video clips using OpenCV and a Convolutional Neural Network (CNN). The system identifies emotions like Happy, Sad, Angry, Fear, Surprise, Disgust, and Neutral from short video files.
download the FER 2013 dataset from kaggle for this project.

dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Angry/
â”‚   â”œâ”€â”€ Disgust/
â”‚   â”œâ”€â”€ Fear/
â”‚   â”œâ”€â”€ Happy/
â”‚   â”œâ”€â”€ Sad/
â”‚   â”œâ”€â”€ Surprise/
â”‚   â””â”€â”€ Neutral/
â””â”€â”€ validation/
    â”œâ”€â”€ Angry/
    â”œâ”€â”€ Disgust/
    â”œâ”€â”€ Fear/
    â”œâ”€â”€ Happy/
    â”œâ”€â”€ Sad/
    â”œâ”€â”€ Surprise/
    â””â”€â”€ Neutral/
After downloading, extract the dataset and place it inside a folder named dataset in the project directory.
The folder structure should look like this:
open_cv/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ emotion_model.h5
â”œâ”€â”€ sample.mp4
â””â”€â”€ video_processing-checkpoint.ipynb
#IF YOU WANT TO SAVE SOMETIME THEN TRY TO SAVE THE BEST MODEL(ALTHOUGH FOR THIS PROJECT THIS IS OPTIONAL)
 Save the best model during training to avoid overfitting:
python
Copy
Edit
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

checkpoint = ModelCheckpoint('best_emotion_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')
early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max')

model.fit(
    train_generator,
    epochs=50,
    validation_data=validation_generator,
    callbacks=[checkpoint, early_stopping]
)
ðŸŽ‰ Results
The program will display real-time emotion detection on video frames and print the sentiment summary at the end.
ðŸ’¡ Technologies Used
Python
OpenCV
TensorFlow/Keras
NumPy
